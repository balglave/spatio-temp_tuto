---
title: "Essential Habitats and Spatio-Temporal Analysis of Marine Species"
subtitle: "Workshop 3"
date: "December 2024"
fontsize: 10pt
bibliography : ["ref.bib"]
csl : ices-journal-of-marine-science.csl
output:
  beamer_presentation:
    theme: "Boadilla"
    colortheme: "default"
    slide_level: 3
    # template: mytemplate.tex
    includes:
      in_header: header-simple-bis.tex
---

### **General Context**  

\begin{itemize}
\item Marine species in temperate waters follow an \textbf{annual life cycle} (Jones, 1968; Secor, 2015).
\item Species use different \textbf{ecological habitats} for specific functions (e.g., reproduction, feeding).
\item \textbf{Essential habitats} are critical habitats for the renewal of marine populations.
\end{itemize}

\begin{center}
\includegraphics[width=0.65\textwidth]{images/essential_habitats.png}
\end{center}

**Key Challenge**

\begin{itemize}
\item Importance of identifying and protecting these habitats (e.g., marine protected areas, fishing closures).
\item Need to understand whether species share \textbf{similar spatio-temporal dynamics} and common essential habitats.
\end{itemize}

---

### **Ecological Objective**

**Identifying spatio-temporal dynamics and essential habitats**  

\begin{itemize}
\item Study \textbf{$p$ marine species} in the Bay of Biscay.
\item Identify \textbf{main spatial and/or temporal variation patterns} (dimension-reduction).
\item Identify \textbf{ecological seasons and essential habitats} (clustering).
\end{itemize}

\smallskip

\quad \ding{224} Leverage advanced analytical tools (\textit{e.g.} EOFs, Tucker decomposition, VAE).

\smallskip

\begin{center}
\includegraphics[width=0.85\textwidth]{images/sole_clust.png}
\end{center}

---

### **Raw data**

Based on a **hierarchical spatio-temporal model** integrating large and heterogeneous datasets from **scientific surveys** and **fishing declarations**

\smallskip

\ding{224} Spatio-temporal predictions of species biomass at **monthly resolution**.

\center

\only<1>{\includegraphics[width=1\textwidth]{images/int_mod_1.png}}

\only<2>{\includegraphics[width=1\textwidth]{images/int_mod_2.png}}

\only<3>{\includegraphics[width=1\textwidth]{images/int_mod_3.png}}

\only<4>{\includegraphics[width=1\textwidth]{images/int_mod_4.png}}

\only<5>{\includegraphics[width=1\textwidth]{images/int_mod_5.png}}

\only<6>{\includegraphics[width=1\textwidth]{images/int_mod_6.png}}

\only<7>{\includegraphics[width=1\textwidth]{images/int_mod_7.png}}

\only<8>{\includegraphics[width=1\textwidth]{images/int_mod_8.png}}

---

### **Raw data**

```{=tex}
\begin{columns}
\begin{column}{0.65\textwidth}

\begin{center}

\includegraphics[width=0.9\textwidth]{images/seabass.png}

\end{center}

\end{column}
\begin{column}{0.35\textwidth}

\scriptsize

Average monthly distribution of sea bass in the Bay of Biscay from 2008 to 2018

\end{column}
\end{columns}
```

---

### **Existing methods and analysis**

\small

\begin{itemize}
\item PCA on spatio-temporal datasets (also called Empirical Orthogonal Functions) ...
\item ... combined with a clustering analysis 
\end{itemize}

\medskip

\pause

\noindent\rule[7pt]{\linewidth}{0.4pt}

Let's denote a spatio-temporal process $S = (S(x,t) ; x \in \mathbb{R}^2, t \in \{ t_1,\cdots,t_p \} )$. \medskip

The temporal average of $S$ in denoted:

$$\overline{\mathbf{s}}^t(x)=\frac{1}{p} \sum_{k=1}^{p} S(x,t_k)$$

The time-centered space-time field:

$$\mathbf{S}'=\left(\mathbf{s}_{t_1}-\overline{\mathbf{s}}^t,...,\mathbf{s}_{t_p}-\overline{\mathbf{s}}^t\right).$$

\bigskip

Then, $\mathbf{S}'$ has the form:

$$\mathbf{S}'=\begin{pmatrix}
S'(x_1,t_1) & S'(x_1,t_2) & \cdots & S'(x_1,t_p)\\
S'(x_2,t_1) & S'(x_2,t_2) & \cdots & S'(x_2,t_p)\\
\vdots &  \ddots & \ddots & \vdots \\
S'(x_n,t_1) & S'(x_n,t_2) & \cdots & S'(x_n,t_p)\\
\end{pmatrix}$$

---

### **Data for EOFs**

\begin{figure}[H]
\centering
\includegraphics[width=1.05\textwidth]{images/input_maps_sole.png}
\caption{(left) Montly spatial log-predictions $\log S(x,t)$ of the hierarchical model. (right) Monthly anomalies of the spatial predictions $S^*(x,t)$. Each panel corresponds to the average distribution of prediction of anomalies for a month over the period 2008 - 2018.}
\label{fig:dataset}
\end{figure}


---

### **Basics of EOF**

The spatio-temporal field is decomposed so that:

$$S'(x,t) = \sum_{m=1}^r p_m(x) \cdot \alpha_m(t) \textcolor{BaptisteGrey}{+ \epsilon_m(x,t)}$$

\medskip

with $r$ the number of dimensions of the EOF ($r \le min(n,p)$), $p_m(x)$ the spatial term of EOF and $\alpha_m(t)$ the temporal term of EOF for dimension $m$. 

$\epsilon_m(x,t)$ is an error term. \bigskip

\underline{Constraints:}

- minimize $E = \sum_m \sum_x \sum_y \epsilon_m(x,t)$

- spatial terms and temporal terms are orthogonal

$$\langle p_i(\cdot) ; p_j(\cdot)  \rangle = 0 \quad i \neq j$$

$$\langle \alpha_i(\cdot) ; \alpha_j(\cdot)  \rangle = 0 \quad i \neq j$$

---

### **Illustration**

\center

\begin{figure}[H]
\centering
\includegraphics[width=1\textwidth]{images/eof_sole.png}
\caption{(Left) Loadings for the two first dimensions of the EOF. (Right) Spatial factors for the two first dimensions of the EOF. Blue dashed vertical lines corresponds to the month of January for each year.}
\end{figure}

---

### **Estimating the spatial and temporal terms**

\large

The spatial ($p_m(x)$) and the temporal terms ($\alpha_m(t)$) are estimated through \underline{eigen-decomposition}:

$$\mathbf S' \mathbf S'^T = \mathbf{C_{S'}} = \mathbf U \boldsymbol \Lambda \mathbf U^T$$

\medskip

or through \underline{singular value decomposition}:

$$\mathbf S' = \mathbf U \boldsymbol \Sigma \mathbf V^T \quad \text{(SVD)}$$

\begin{itemize}

\item $\mathbf{C_{S'}}$ is the covariance function of $\mathbf S'$

\item  $\mathbf U_{(n \times r)}$ contains the spatial factors ($p_m(x)$), 

\item $\boldsymbol \Lambda_{(r \times r)}$ contains the eigen values and $\boldsymbol \Sigma_{(r \times r)}$ contains the singular values of $\mathbf S'$. 

\smallskip

\scriptsize

These quantifies the percentage of variance captured by each dimension. \\
They are diagonal matrices with $\boldsymbol \Lambda = \boldsymbol \Sigma^2$

\large

\item $\mathbf V_{(p \times r)}$ contains the temporal loadings ($\alpha_m(t)$)

\end{itemize}

---

### **Clustering locations and time steps**

\center

\medskip

HCPC on $\mathbf{U}$ (spatial factors) \ding{224} identify \textbf{functional habitats} (left and right)

\medskip

HCPC on $\mathbf{V}$ (temporal loadings) \ding{224} identify \textbf{ecological seasons} (right)

\medskip

\begin{figure}[H]
\centering
\includegraphics[width=1\textwidth]{images/sole_clust.png}
\caption{Essential habitats and associated seasons. (Left column) Mapping spatial clusters using eigenvectors to identify essential habitats. (Right column) Projection of the loading factors (seasons) and the eigen vectors (spatial clusters) on the two first dimensions of the EOF.}
\end{figure}

---

### **Limits of the method and steps forwards**

- Hypothesis of \textbf{linearity} of the PCA \medskip

- Hypothesis of \textbf{stationarity} \medskip

- Single species \medskip

\noindent\rule[7pt]{\linewidth}{0.4pt}

\medskip

Proposal to this team \ding{224} Explore other methods to perform dimension-reduction and identify essential habitats / ecological seasons. \medskip

- To move to multivariate analysis \medskip

\quad \quad \quad \ding{224} \textbf{Tensor decomposition technics} (Tucker, CPD)

\medskip \medskip

- A new method (not so new now) to perform dimension-reduction \medskip

\quad \quad \quad \ding{224} \textbf{Variational Auto-Encoder} (VAE) 

---

### **Move to multivariate analysis**

\begin{itemize}
\item An option would be to bind the matrices of the several species by raw or by columns (see  \textcolor{blue}{\underline{\href{https://shs.hal.science/LAB-STICC_DMID/hal-04693871v2}{link}}}) \pause
\item But this faces limits, let's try decomposition methods based on tensors! \pause
\item For instance, investigate the Tucker decomposition:
\end{itemize}
$$\mathcal{X} \approx \mathcal{C} \times_1 \mathbf{Q}^1 \times_2 \mathbf{Q}^2 \times_3 \mathbf{Q}^3$$
\begin{columns}
\begin{column}{0.45\textwidth}

\footnotesize

\begin{itemize}[label=]
\item $\mathcal{X} \in \mathbb{R}^{n_1 \times n_2 \times n_3}$ is the tensor
\item $\mathbf{Q}^k$ are the factor matrix
\item $\mathcal{C} \in \mathbb{R}^{m_1 \times m_2 \times m_3}$ is the core tensor
\end{itemize}

\end{column}
\begin{column}{0.55\textwidth}

\begin{figure}[H]
\centering
\includegraphics[width=1\textwidth]{images/tucker_svd.png}
\end{figure}

\end{column}
\end{columns}

\pause

\begin{itemize}[label=\ding{212}]
\item $n_1$ would be the \textbf{locations} of the spatial predictions grid
\item $n_2$ would be the \textbf{number of time steps} in the time series
\item $n_3$ would be the \textbf{number of species}
\end{itemize}

---

### **Short introduction to VAE**

\small

A very good introduction (thanks to Felix Cheysson and Tristan Mary-Huard!) that serves as basis for the next slides:

\begin{center}
\textcolor{blue}{\underline{\url{https://stateofther.netlify.app/post/variational-autoencoder-with-torch/}}}
\end{center}

\begin{figure}[H]
\centering
\includegraphics[width=0.65\textwidth]{images/vae0.png}
\end{figure}

And a very nice application here: \textcolor{blue}{\underline{\url{https://arxiv.org/pdf/2312.00456}}}

---

### **Short introduction to VAE**

An autoencoder, **encoder-decoder** pair $(e, d)$, aims to minimise the reconstruction error measure between an input data $x \in \mathcal{X}$ and the encoded-decoded data $d(e(x)) \in \mathcal{X}$:

$$
\left(e^*, d^*\right)=\underset{(e, d) \in E \times D}{\arg \min } L(x, d(e(x)))
$$

\begin{figure}[H]
\centering
\includegraphics[width=0.65\textwidth]{images/vae1.png}
\end{figure}

---

### **Short introduction to VAE**

- Denote $z=e(x) \in \mathcal{Z}$ the encoded data, call it a **latent variable**.

- **Problem**: without any constraint on the encoder-decoder pair $(e, d)$ (e.g. neural networks), the autoencoder may lead to gross overfitting.

- Example: mapping $\left(x_1, \ldots, x_n\right)$ to integers $(1, \ldots, n)$ and back.

- This leads to a lack of interpretable and exploitable structure in the latent space $\mathcal{Z}$, without generative purpose.

\begin{figure}[H]
\centering
\includegraphics[width=1\textwidth]{images/vae2.png}
\end{figure}

---

### **Short introduction to VAE**

- **Idea**: Introduce probabilistic model on $(x, z)$ such that the latent space $\mathcal{Z}$ becomes structured.

- Akin to a regularisation during the training process, of the form

$$
\left(e^*, d^*\right)=\underset{(e, d) \in E \times D}{\arg \min } L(x, d(e(x)))+D_{\mathrm{KL}}(p(z) \| \mathcal{N}(0,1)) .
$$

\begin{figure}[H]
\centering
\includegraphics[width=0.5\textwidth]{images/vae3.png}
\end{figure}

---

### **What do we do with VAE?**

- All the estimation is performed through variational inference (see website slides) \ding{224} see the \textcolor{blue}{\underline{\href{https://stateofther.netlify.app/post/variational-autoencoder-with-torch/}{website}}} for more details

- **Objective:** represent complex information into a lower rank space

\medskip

\begin{center}
\textbf{Example of the MNIST dataset}
\end{center}

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{images/mnist_vae.png}
\end{figure}

### **Ideas for this workshop**

- Perform the same for spatio-temporal distribution of marine species

```{=tex}
\begin{columns}
\begin{column}{0.5\textwidth}

\begin{center}

\includegraphics[width=1\textwidth]{images/seabass.png}

\end{center}

\end{column}
\begin{column}{0.5\textwidth}

\underline{Several possibilities:} \medskip

\ding{224} Identify the time-steps that have similar spatial distribution

\medskip

\ding{224} Identify the locations that have similar time-series

\medskip

\ding{224} Look at the inference side?

\smallskip

\begin{center}
\includegraphics[width=0.5\textwidth]{images/interrogation.png}
\end{center}

\end{column}
\end{columns}
```

---

\center

\huge

\textbf{Let's move to code!}
